---
lang: en
---

Benchmarking Amazon\'s Aurora \| Lars Cromley

::: {.section .section}
::: container
::: nav-left
[](https://cromleylabs.com){.nav-item}

# Lars Cromley {#lars-cromley .title .is-4}
:::

::: nav-right
[[]{.icon}](/about){.level-item}[[]{.icon}](/disclaimer){.level-item}[[]{.icon}](https://github.com/callmeradical){.level-item}[[]{.icon}](https://twitter.com/callmeradical){.level-item}[[]{.icon}](/index.xml){.level-item}
:::
:::
:::

::: {.section .section}
::: container
## September 7, 2016 {#september-7-2016 .subtitle .is-6}

# Benchmarking Amazon\'s Aurora {#benchmarking-amazons-aurora .title}

::: content
I saw this study by the folks over at [Google and their 2nd Generation
Cloud
SQL](https://cloudplatform.googleblog.com/2016/08/Cloud-SQL-Second-Generation-performance-and-feature-deep-dive.html).

The results they posted didn't exactly mirror what I saw when running
the benchmarks for myself. You can get the raw data here @
[Github.](https://github.com/2ndWatch/aurora_benchmark)

Everything was stood up using Terraform, the benchmark tests were
conducted using Sysbench, and all data was plotted using R.

Since we didn't have access to Google's original data, we provided some
overlays in the post as an easy visual comparison. However the data used
to produce all of those graphs as well as additional data is in the
repo.

[Read More @
2ndwatch.com](http://2ndwatch.com/blog/benchmarking-amazon-aurora/)
:::
:::
:::

::: {.section .section}
::: container
::: {#disqus_thread}
:::

Please enable JavaScript to view the [comments powered by
Disqus.](https://disqus.com/?ref_noscript){rel="nofollow"}
:::
:::

::: {.section .section}
::: {.container .has-text-centered}
Â© [Lars Cromley](https://github.com/callmeradical) 2017
:::
:::
